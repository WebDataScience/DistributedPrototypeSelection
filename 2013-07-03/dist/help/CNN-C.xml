<method>

	<name>Condensed Nearest Neighbor</name>

	<reference>  

		<ref>P. E. Hart. The condensed nearest neighbour rule. IEEE Transactions on Information Theory 18:5 (1968) 515-516.</ref>

	</reference>

	<generalDescription>  

		<type>Preprocess Method. Data Reduction. Instance Selection. Incremental.</type>

		<objective>Reduce the size of the training set without losing precision or accuracy in order to a posterior classification</objective>

		<howWork>This algorithm finds
	a subset S of the training set T such that every member of T is closer to a
	member of S of the same class than to a member of S of a different class. It
	begins by randomly selecting one instance belonging to each output class from
	T and putting them in S. Then each instance in T is classified using only the
	instances in S. If an instance is misclassified, it is added to S, thus ensuring
	that it will be classified correctly. This process is repeated until there are no
	instances in T that are misclassified. This algorithm ensures that all instances
	in T are classified correctly, though it does not guarantee a minimal set.</howWork>

		<parameterSpec>  

			<param>Number of neighbors: Integer value. Number of nearest instances considered to classify an example using the K-Nearest Neighbor Rule</param>
			<param>Distance Function: K-NN implements two distance functions. a) Euclidean with normalized attributed and b) HVDM (see paper D.R. Wilson, T.R. Martinez. Reduction Tecniques For Instance-Based Learning Algorithms. Machine Learning 38:3 (2000) 257-286.)</param>

		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes</discretized>

			<integer>Yes</integer>

			<nominal>Yes</nominal>

			<valueLess>No</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Classification 
Method: IS-CNN
Dataset: iris
Training set: iris-10-1tra.dat
Parameters: default values

We can see output set in Experiment\Results\IS-CNN:

@relation iris
@attribute sepalLength real [4.3, 7.9]
@attribute sepalWidth real [2.0, 4.4]
@attribute petalLength real [1.0, 6.9]
@attribute petalWidth real [0.1, 2.5]
@attribute class {Iris-setosa, Iris-versicolor, Iris-virginica}
@data
5.4,3.4,1.7,0.2,Iris-setosa
5.9,3.0,4.2,1.5,Iris-versicolor
6.1,2.8,4.0,1.3,Iris-versicolor
5.8,2.7,5.1,1.9,Iris-virginica
5.7,2.5,5.0,2.0,Iris-virginica
</example>

</method>