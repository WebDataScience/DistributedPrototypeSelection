<method>

	<name>Genetic Selection of Linguistic Rule Bases</name>

	<reference>  

		<ref>O. Cord&#xF3;n and F. Herrera, A Three-Stage Evolutionary Process for Learning Descriptive and Approximative Fuzzy Logic Controller Knowledge Bases from Examples, International Journal of Approximate Reasoning 17:4 (1997) 369-407.</ref>

		<ref>H. Ishibuchi, K. Nozaki, N. Yamamoto and H. Tanaka, Selecting Fuzzzy If-Then Rules for Classification Problems Using Genetic Algorithms, IEEE Trans. on Fuzzy Systems 3:3 (1995) 260-270.</ref>
		
	</reference>

	<generalDescription>  

		<type>Genetic Fuzzy Rule Learning.</type>

		<objective>A Genetic Algorithm is used to select the most cooperative rules of the Fuzzy Rule Set.</objective>

		<howWork>Given a Mamdani Fuzzy Rule Set obtained by a Fuzzy Rule Base System this method searches
		for the best rules in this set in order to achieve the lower mean square error (MSE). 
		This simplification process is based on a 
         binary-coded GA with fixed-length chromosomes. Considering the rules contained 
         in the rule set derived from the previous step counted from 1 to m, an m-bit string 
         C = (c1, ..., cm) represents a subset of candidate rules to form the fuzzy rule base 
         finally obtained as this stage output such that if ci = 1 then Ri is included in the selected rule set.

         The selection of the individuals is developed using the Baker&apos;s stochastic universal 
         sampling procedure together with an elitist selection scheme, and the recombination 
         is put into effect using the classical binary multipoint crossover (performed at two points) 
         and uniform mutation operators. The fitness function is composed of the mean square error 
         over the training data set (to reward the similarity between the model and the data set) 
         and a covering measure (to penalize the lack of the completeness property obtained in the previous stage). 
         The initial population is generated by introducing a chromosome representing the complete previously 
         obtained rule set, i.e, all genes set to 1. The remaining chromosomes are selected at random.
		</howWork>

		<parameterSpec>  

			<param>Number of Iterations: Is the number of generations of the GA</param>
			<param>Population Size: Is the number of chromosomes.</param>
			<param>Tau parameter for the minimun maching degree required to the KB: The MSE
			is minimized if the Rule Base achieves a covering degree greater than Tau. Otherwise the 
			chromosome gets a maximum value of fitness.</param>
			<param>Rate of rules to estimate the niche radio: Is the percentage of rules that are considered
			to belong to a niche.</param>
			<param>Beta parameter for the Power Law: Is is used to penalize the fitness if the chromosome is
			found to be in a niche,</param>
			<param>Type of Fitness Function: There are two types of fitness functions, the first one uses the
			MSE and the second one weights the MSE by the deviation of the covering degree of the rule base with regard to
			the optimal value 1</param>
			<param>Cross Probability: Is the probability to apply the multipoint crossover.  It is a float value between 0 and 1.</param>
			<param>Mutation Probability: Is the probability to apply the uniform mutation. It is a float value between 0 and 1.</param>

		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes (only with numerical)</discretized>

			<integer>Yes</integer>

			<nominal>No</nominal>

			<valueLess>Yes</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Regression
        Method: Post-Rules-Selection
        Dataset: ele1
        Training set: ele1-10-1tra.dat
        Test set: ele1-10-1tst.dat
        Test Show results: StatChekMO
        Parameters: default values

        After the execution of RunKeel.jar we can see into the experiment\results\StatCheckMO folder the regression results for the test set:

		TEST RESULTS
		============
		Model = daily_average_cost_of_the_electry_energy_in_spain_in_2003 
		MSE of all folds:
		Fold 0 : 0.2271275667883263 
		Global MSE:
		0.2271275667883263 
		Global stdev:
		0.0 
		
		TRAIN RESULTS
		============
		Model = daily_average_cost_of_the_electry_energy_in_spain_in_2003 
		MSE of all folds:
		Fold 0 : 0.11466956426131057 
		Global MSE:
		0.11466956426131057 
		Global stdev:
		0.0 

		We can also see the output rule base in Experiment\Results\Post-Rules-Selection\Regr-Fuzzy-WangMendel.

</example>

</method>