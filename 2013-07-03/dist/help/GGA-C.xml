<method>

	<name>Generational Genetic Algorithm for Instance Selection</name>

	<reference>  

		<ref>J.R. Cano, F. Herrera, M. Lozano. Using evolutionary algorithms as instance selection for data reduction in KDD: An experimental study. IEEE Transaction on Evolutionary Computation 7:6 (2003) 561-575</ref>

	</reference>

	<generalDescription>  

		<type>Preprocess Method. Data Reduction. Instance Selection. Evolutionary</type>

		<objective>Reduce the size of the training set without losing precision or accuracy in order to a posterior classification</objective>

		<howWork>Application of a Generational Genetic Algorithm to the Instance Selection Problem.</howWork>

		<parameterSpec>
			<param>1 to 0 Mutation Probability: Real value. Probability associated to a change from 1 to 0 in the mutation operator.</param>
			<param>0 to 1 Mutation Probability: Real value. Probability associated to a change from 0 to 1 in the mutation operator.</param>
			<param>Cross Probability: Real value. Probability associated to perform a crossover operator</param>
			<param>Population Size: Integer value. Number of chromosome belonging to the population (if it is odd, elitism is applied).</param>
			<param>Number of Evaluations: Integer value. Maximal number of evaluations allowed in the run of the algorithm</param>
			<param>Alfa Equilibrate Factor: Real value. Trade-off factor that controls the balaning between reduction and accuracy</param>
			<param>Selection Mechanism: Scheme of selection of parents. Based on Baker or Binary Tournament.</param>
			<param>Number of neighbors: Integer value. Number of nearest instances considered to classify an example using the K-Nearest Neighbor Rule</param>
			<param>Distance Function: K-NN implements two distance functions. a) Euclidean with normalized attributed and b) HVDM (see paper D.R. Wilson, T.R. Martinez. Reduction Tecniques For Instance-Based Learning Algorithms. Machine Learning 38:3 (2000) 257-286.)</param>		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes</discretized>

			<integer>Yes</integer>

			<nominal>Yes</nominal>

			<valueLess>No</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Classification 
Method: IS-GGA
Dataset: iris
Training set: iris-10-1tra.dat
Parameters: default values

We can see output set in Experiment\Results\IS-GGA:

@relation iris
@attribute sepalLength real [4.3, 7.9]
@attribute sepalWidth real [2.0, 4.4]
@attribute petalLength real [1.0, 6.9]
@attribute petalWidth real [0.1, 2.5]
@attribute class {Iris-setosa, Iris-versicolor, Iris-virginica}
@data
4.4,3.0,1.3,0.2,Iris-setosa
6.4,3.2,4.5,1.5,Iris-versicolor
6.1,2.8,4.0,1.3,Iris-versicolor
6.8,3.0,5.5,2.1,Iris-virginica
5.8,2.7,5.1,1.9,Iris-virginica
</example>

</method>