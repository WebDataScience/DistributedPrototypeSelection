<method>

	<name>Intelligent Genetic Algorithm for Edition</name>

	<reference>  

		<ref>S.Y. Ho, C.C. Liu, S. Liu. Design of an optimal nearest neighbor classifier using an intelligent genetic algorithm. Pattern Recognition Letters 23 (2002) 1495-1503</ref>

	</reference>

	<generalDescription>  

		<type>Preprocess Method. Data Reduction. Instance Selection. Evolutionary</type>

		<objective>Reduce the size of the training set without losing precision or accuracy in order to a posterior classification</objective>

		<howWork>Application of a Generational Genetic Algorithm to the Instance Selection Problem using an intelligent crossover operator based on orthogonal arrays.</howWork>

		<parameterSpec>
			<param>1 to 0 Mutation Probability: Real value. Probability associated to a change from 1 to 0 in the mutation operator.</param>
			<param>0 to 1 Mutation Probability: Real value. Probability associated to a change from 0 to 1 in the mutation operator.</param>
			<param>Population Size: Integer value. Number of chromosome belonging to the population.</param>
			<param>Number of Evaluations: Integer value. Maximal number of evaluations allowed in the run of the algorithm</param>
			<param>Alfa Equilibrate Factor: Real value. Trade-off factor that controls the balaning between reduction and accuracy</param>
			<param>Number of neighbors: Integer value. Number of nearest instances considered to classify an example using the K-Nearest Neighbor Rule</param>
			<param>Distance Function: K-NN implements two distance functions. a) Euclidean with normalized attributed and b) HVDM (see paper D.R. Wilson, T.R. Martinez. Reduction Tecniques For Instance-Based Learning Algorithms. Machine Learning 38:3 (2000) 257-286.)</param>		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes</discretized>

			<integer>Yes</integer>

			<nominal>Yes</nominal>

			<valueLess>No</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Classification 
Method: IS-IGA
Dataset: iris
Training set: iris-10-1tra.dat
Parameters: default values

We can see output set in Experiment\Results\IS-GGA:

@relation iris
@attribute sepalLength real [4.3, 7.9]
@attribute sepalWidth real [2.0, 4.4]
@attribute petalLength real [1.0, 6.9]
@attribute petalWidth real [0.1, 2.5]
@attribute class {Iris-setosa, Iris-versicolor, Iris-virginica}
@data
4.4,3.0,1.3,0.2,Iris-setosa
6.4,3.2,4.5,1.5,Iris-versicolor
6.1,2.8,4.0,1.3,Iris-versicolor
6.8,3.0,5.5,2.1,Iris-virginica
5.8,2.7,5.1,1.9,Iris-virginica
</example>

</method>