<method>

	<name>Friedman Alligned Test and Post-Hoc Procedures</name>

	<reference>  

	<ref>J. Zar, Biostatistical Analysis, Prentice Hall, Upper Saddle River, New Jersey, 1999.</ref>
	<ref>D. Sheskin, Handbook of parametric and nonparametric statistical procedures. Chapman and Hall/CRC, 2003. </ref>
	<ref>J. Demsar, Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research 7 (2006) 1-30</ref>

	</reference>

	<generalDescription>  

		<type>Application of non-parametric tests.</type>

		<objective>Execution of the non-parametric Friedman test and post-hoc tests for comparison of the global performance of several regression methods.</objective>

		<howWork>
		The Friedman test is based on n sets of ranks, one set for each data set in our case; and the performances of the algorithms analyzed are ranked separately
		for each data set. Such a ranking scheme allows for intra-set comparisons only, since inter-set comparisons are not meaningful. When the number of algorithms
		for comparison is small, this may pose a disadvantage. In such cases, comparability among data sets is desirable and we can employ the method of aligned ranks.
		
		In this technique, a value of location is computed as the average performance achieved by all algorithms in each data set. Then, it calculates the difference 
		between the performance obtained by an algorithm and the value of location. This step is repeated for algorithms and data sets. The resulting differences,
		called aligned observations, which keep their identities with respect to the data set and the combination of algorithms to which they belong, are then ranked
		from 1 to kn relative to each other. Then, the ranking scheme is the same as that employed by a multiple comparison procedure which employs independent
		samples; such as the Kruskal-Wallis test. The ranks assigned to the aligned observations are called aligned ranks.
		</howWork>

		<parameterSpec>  
		<param>Apply-Iman-Davenport: It can takes the value YES or NO if the user desires to apply the Iman and Davenport test</param>
		<param>Apply-Bonferroni-Dunn: It can takes the value YES or NO if the user desires to apply the Bonferroni-Dunn test</param>
		<param>Apply-Holm: It can takes the value YES or NO if the user desires to apply the Holm test</param>
		<param>Apply-Hochberg: It can takes the value YES or NO if the user desires to apply the Hochberg test</param>
		<param>Apply-Hommel: It can takes the value YES or NO if the user desires to apply the Hommel test</param>
		<param>Apply-Holland: It can takes the value YES or NO if the user desires to apply the Holland test</param>
		<param>Apply-Rom: It can takes the value YES or NO if the user desires to apply the Rom test</param>
		<param>Apply-Finner: It can takes the value YES or NO if the user desires to apply the Finner test</param>
		<param>Apply-Li: It can takes the value YES or NO if the user desires to apply the Li test</param>
		</parameterSpec>

		<properties>
		</properties>

	</generalDescription>

	<example>Problem type: Regression 
Methods to compare: Regr-MLPerceptronConj-Grad vs Regr-LinearLMS vs Regr-Fuzzy-WM
Datasets: daily-electric-energy, Ele1, friedman, machine-cpu
Default Parameters (all the post-hoc tests are applied)
Type of partitions: k-fold, k=10

After the execution of RunKeel.jar we can see into the ./results/Stat-Regr-FriedmanAlligned/TSTRegr-MLPerceptronConj-GradvsRegr-LinearLMSvsRegr-Fuzzy-WM folder the results0s0.stat file:

FriedmanAlligned Test, Regression
Regression error in each foldfold:
Algorithm = Regr-MLPerceptronConj-Grad
Fold 0 : 0.13358883028152593 
Fold 1 : 0.17175051992536386 
Fold 2 : 0.15476569415752764 
Fold 3 : 0.13145726997608692 
Fold 4 : 0.2515275751755297 
Fold 5 : 0.1584639781278857 
Fold 6 : 0.112863992835126 
Fold 7 : 0.13594607912315596 
Fold 8 : 0.19115595561944598 
Fold 9 : 0.17337698297007884 
Mean Value: 0.16148968781917267
Algorithm = Regr-MLPerceptronConj-GradRegr-LinearLMS
Fold 0 : 0.13276224210953563 
Fold 1 : 0.18120381885508868 
Fold 2 : 0.182370405802494 
Fold 3 : 0.16173335412244483 
Fold 4 : 0.22907270759939843 
Fold 5 : 0.1523434941533297 
Fold 6 : 0.11773693421451363 
Fold 7 : 0.14663031088893072 
Fold 8 : 0.221371320386903 
Fold 9 : 0.17624151293476897 
Mean Value: 0.17014661010674076
Algorithm = Regr-MLPerceptronConj-GradRegr-LinearLMSRegr-Fuzzy-WM
Fold 0 : 0.25075271468396515 
Fold 1 : 0.2818377224596541 
Fold 2 : 0.302755945842815 
Fold 3 : 0.13328313725389387 
Fold 4 : 0.27549722538369426 
Fold 5 : 0.17672332649230282 
Fold 6 : 0.1941539042725541 
Fold 7 : 0.16673710401211578 
Fold 8 : 0.19748037076941652 
Fold 9 : 0.19001148599258205 
Mean Value: 0.21692329371629934


and a LaTeX output file "output.tex" where the results of the application of the test are provided.

</example>

</method>
