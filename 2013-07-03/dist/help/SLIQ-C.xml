<method>

	<name>SLIQ Decision Tree</name>

	<reference>  

		<ref>M. Mehta, R. Agrawal, J. Rissanen. SLIQ: A Fast Scalable Classifier for Data Mining. Proceedings of the 5th International Conference on Extending Database Technology. (1996) 18-32.</ref>

	</reference>

	<generalDescription>  

		<type>Classification model by decision trees</type>

		<objective>To determine a decision tree that on the basis of answers to questions about the input attributes predicts correctly the value of the target attribute</objective>

		<howWork>SLIQ builds decision trees through ordered lists of attributes and instances and measuring the information gain in the selection of every attribute by means of the GINI index. It uses a width-squeme of tree growing and it is prepared to tackle with numeric attriutes. Nominal attributes are dealed considering all possible combinations of subsets and dividing the complete sets of values for each attributes into two subsets. Attributes with many values are treated in a greedy way.
		SLIQ implements sequentially two tree prune schemes based on the minimum description lenght principle.
		</howWork>

		<parameterSpec>  

		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes</discretized>

			<integer>Yes</integer>

			<nominal>Yes</nominal>

			<valueLess>Yes</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Classification 
Method: SLIQ
Dataset: iris
Training set: iris-10-1tra.dat
Test set: iris-10-1tst.dat
Test Show results: StatChekCL
Parameters: default values

After the execution of RunKeel.jar we can see into the experiment\results\StatCheckCL folder the classification results for the test set:

Summary of data, Classifiers: iris
Fold 0 : CORRECT=0.9333333333333333 N/C=0.0 
Global Classification Error + N/C:
0.06666666666666667 
Correctly classified:
0.9333333333333333 
Global N/C:
0.0 

We can also see the output and target classes for each case of the test set (result0.tst) in Experiment\Results\Clas-C4.5:

@relation  iris_plants_database
@attribute sepalLength real[4.3,7.9]
@attribute sepalWidth real[2.0,4.4]
@attribute petalLength real[1.0,6.9]
@attribute petalWidth real[0.1,2.5]
@attribute class{Iris-setosa,Iris-versicolor,Iris-virginica}
@inputs sepalLength,sepalWidth,petalLength,petalWidth
@outputs class
@data
Iris-setosa Iris-setosa
Iris-setosa Iris-setosa
Iris-setosa Iris-setosa
Iris-setosa Iris-setosa
Iris-setosa Iris-setosa
Iris-versicolor Iris-versicolor
Iris-versicolor Iris-versicolor
Iris-versicolor Iris-versicolor
Iris-versicolor Iris-versicolor
Iris-versicolor Iris-versicolor
Iris-virginica Iris-virginica
Iris-virginica Iris-virginica
Iris-virginica Iris-virginica
Iris-virginica Iris-virginica
Iris-versicolor Iris-virginica

And the decision tree model (result0e0.txt) in Experiment\Results\Clas-C4.5:

@relation  iris_plants_database
@attribute sepalLength real[4.3,7.9]
@attribute sepalWidth real[2.0,4.4]
@attribute petalLength real[1.0,6.9]
@attribute petalWidth real[0.1,2.5]
@attribute class{Iris-setosa,Iris-versicolor,Iris-virginica}
@inputs sepalLength,sepalWidth,petalLength,petalWidth
@outputs class
@data

@decisiontree

if ( petalWidth &lt;= 0.600000 ) then
{
	class = "Iris-setosa"
}
elseif ( petalWidth &gt; 0.600000 ) then
{
	if ( petalWidth &lt;= 1.700000 ) then
	{
		if ( petalLength &lt;= 4.900000 ) then
		{
			class = "Iris-versicolor"
		}
		elseif ( petalLength &gt; 4.900000 ) then
		{
			if ( petalWidth &lt;= 1.500000 ) then
			{
				class = "Iris-virginica"
			}
			elseif ( petalWidth &gt; 1.500000 ) then
			{
				class = "Iris-versicolor"
			}
		}
	}
	elseif ( petalWidth &gt; 1.700000 ) then
	{
		class = "Iris-virginica"
	}
}
@TotalNumberOfNodes 4
@NumberOfLeafs 5

@NumberOfItemsetsTraining 135
@NumberOfCorrectlyClassifiedTraining 133
@PercentageOfCorrectlyClassifiedTraining 98.51852%
@NumberOfInCorrectlyClassifiedTraining 2
@PercentageOfInCorrectlyClassifiedTraining 1.4814814%

@NumberOfItemsetsTest 15
@NumberOfCorrectlyClassifiedTest 14
@PercentageOfCorrectlyClassifiedTest 93.333336%
@NumberOfInCorrectlyClassifiedTest 1
@PercentageOfInCorrectlyClassifiedTest 6.6666665%

@ElapsedTime 0:0:0
</example>

</method>
