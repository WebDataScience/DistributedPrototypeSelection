<method>

	<name>Tomek's modification of Condensed Nearest Neighbor</name>

	<reference>  

		<ref>I. Tomek. Two modifications of CNN. IEEE Transactions on Systems, Man and Cybernetics 6 (1976) 769-772.</ref>

	</reference>

	<generalDescription>  

		<type>Preprocess Method. Data Reduction. Instance Selection. Incremental.</type>

		<objective>Reduce the size of the training set without losing precision or accuracy in order to a posterior classification</objective>

		<howWork>Prior to the application of the CNN rule, this modification obtains an instance set which contains only
		instances beloning to spaces near to decision boundaries.</howWork>

		<parameterSpec>  

			<param>Number of neighbors: Integer value. Number of nearest instances considered to classify an example using the K-Nearest Neighbor Rule</param>
			<param>Distance Function: K-NN implements two distance functions. a) Euclidean with normalized attributed and b) HVDM (see paper D.R. Wilson, T.R. Martinez. Reduction Tecniques For Instance-Based Learning Algorithms. Machine Learning 38:3 (2000) 257-286.)</param>

		</parameterSpec>

		<properties>

			<continuous>Yes</continuous>

			<discretized>Yes</discretized>

			<integer>Yes</integer>

			<nominal>Yes</nominal>

			<valueLess>No</valueLess>

			<impreciseValue>No</impreciseValue>

		</properties>

	</generalDescription>

	<example>Problem type: Classification 
Method: IS-CNN
Dataset: iris
Training set: iris-10-1tra.dat
Parameters: default values

We can see output set in Experiment\Results\IS-CNN:

@relation iris
@attribute sepalLength real [4.3, 7.9]
@attribute sepalWidth real [2.0, 4.4]
@attribute petalLength real [1.0, 6.9]
@attribute petalWidth real [0.1, 2.5]
@attribute class {Iris-setosa, Iris-versicolor, Iris-virginica}
@data
5.4,3.4,1.7,0.2,Iris-setosa
5.9,3.0,4.2,1.5,Iris-versicolor
6.1,2.8,4.0,1.3,Iris-versicolor
5.8,2.7,5.1,1.9,Iris-virginica
5.7,2.5,5.0,2.0,Iris-virginica
</example>

</method>